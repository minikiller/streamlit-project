{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用于测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = ['01', '02',\"20\"]\n",
    "max_value = max(my_list, key=int)\n",
    "print(max_value)  # Output: '02'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_int = int(max_value)\n",
    "next_int = max_int + 1\n",
    "next_value = str(next_int).zfill(len(max_value))\n",
    "print(next_value)  # Output: '03'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['02_2023年03月.py', '01_2023年02月.py', '03_2023年04月.py', '04_2022年03月.py', '00_03_2021年03月.py']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "directory_path = '../pages'  # replace with your directory path\n",
    "file_names = glob.glob(directory_path + '/*')\n",
    "\n",
    "print([os.path.basename(file) for file in file_names])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'05'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me=len(file_names)\n",
    "str(me).zfill(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pages/05_.py'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"pages/\"+str(len(file_names)).zfill(2)+\"_\"+\".py\"\n",
    "file_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Define the date ranges\n",
    "date_ranges = [(datetime(2021, 1, 1), datetime(2021, 7, 1)),\n",
    "               (datetime(2021, 7, 1), datetime(2022, 1, 1)),\n",
    "               (datetime(2022, 1, 1), datetime(2022, 7, 1)),\n",
    "               (datetime(2022, 7, 1), datetime(2023, 1, 1)),\n",
    "               (datetime(2023, 7, 1), datetime(2023, 7, 1)),\n",
    "               ]\n",
    "\n",
    "file_dict = {\"20210101\": \"Hist_20210101_20210701\", \"20210701\": \"Hist_20210701_20220101\",\n",
    "             \"20220101\": \"Hist_20220101_20220701\", \"20220701\": \"Hist_20220701_20230101\",\n",
    "             \"20230101\": \"Hist_20230101_20230701\",  }\n",
    "\n",
    "def get_file_name(input_date):\n",
    "    for date_range in date_ranges:\n",
    "        # Check if the datetime is within the range\n",
    "        if date_range[0] <= input_date < date_range[1]:\n",
    "            result = date_range[0]\n",
    "            print(\"Date is within the range\")\n",
    "            break\n",
    "        # else:\n",
    "        #     print(\"Date is outside the range\")\n",
    "    return result.strftime('%Y%m%d')\n",
    " \n",
    "\n",
    "dt=datetime(2022, 3, 1)\n",
    "file_dict[get_file_name(dt)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../data/hist/Hist_20210101_20210701.csv\")\n",
    "# write to HDF5 file\n",
    "# df.to_hdf('./example.h5', key='df', mode='w', format='table')\n",
    "# 将DataFrame保存到压缩的HDF5文件中\n",
    "df.to_hdf('data.h5', key='data', mode='w',\n",
    "          format='table', complib='blosc', complevel=9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 从压缩的HDF5文件中读取数据\n",
    "# df_hdf = pd.read_hdf('data.h5', key='data')\n",
    "\n",
    "# # 打印DataFrame\n",
    "# print(df_hdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=\"dfdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str=f\"\"\"\\\n",
    "import data {data}\n",
    "    hello\\\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f351471582b817a4d3d9046ffbd2576aca0eb23cd0065bcd9755f9ab2c258589"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
